\section{Conclusion}
\label{sec:conclusion}

In this paper, we examined the current state of capability-based access control systems. We examined some of their uses, with an emphasis in applications in the Operating Systems domain. In regard to these applications, we have found an emphasis in the versatility and ease of security obtained using capabilities in the literature. However, the analysis regarding performance and the trade offs to be made between these systems has been lacking. Towards that end, we created a means of benchmarking individual capability systems, so that they may be compared to one another.

To demonstrate this system in practice, we implemented a version of the CapBAC distributed capability system, and a modification to a separate category of capability. By doing so, we found that at least for the particular network configurations and workloads we tested, the original design of CapBAC is inferior to a simple modification of it. While it is entirely conceivable that the modified version is not as suited for the setup of the particular conditions and hardware the authors of CapBAC had in mind, there is no way to say for certain due to the lack of detail in the original work. This example demonstrates the poor state of performance information available in capability research. With CapBAC being one of the few systems that even provides capability performance metrics in the first place, frameworks such as ours are direly needed.

In the future, other capability categories can be implemented in our system, and used in various network or local configurations to see how their changed behavior is reflected in performance. The next immediate logical step would likely be switching to non-blocking networking, so that larger, off-the-shelf network simulators may be used to integrate the system into more complex configurations. Once this is done, more thorough inquiries into the potential effects of capability system structures on performance can readily be measured, through the varying of variables in self-contained experiments, without the need for constructing entire operating systems (or other access control-using systems) to do so. Given the trends towards systems that are progressively more heterogeneous, distributed, and security-critical in nature, being able to readily asses the performance of these systems is a problem worth addressing now, as they are built, before mistakes are made and ingrained into the systems we build.